# ğŸ“¡ OrquestraÃ§Ã£o de Pipeline com Apache Airflow

Esta etapa descreve como o projeto **MovieStream Analytics** utiliza o Apache Airflow para orquestrar a execuÃ§Ã£o do pipeline de dados com DBT, garantindo agendamentos automÃ¡ticos, modularidade e controle total do fluxo.

## âœ… Objetivo

Orquestrar a execuÃ§Ã£o dos modelos do DBT (staging, marts, testes) de forma automatizada e escalÃ¡vel via DAGs no Airflow.

## ğŸ§± Estrutura

- DAG `dbt_pipeline_dag` e `dbt_pipeline_dag_modular` com as tarefas:
  - `run_dbt_staging`
  - `run_dbt_marts`
  - `run_dbt_tests`
- Agendamento diÃ¡rio Ã s 8h UTC e tambÃ©m @daily
- Comandos executados diretamente no container Docker via `BashOperator`

## ğŸ“ Local dos arquivos

- DAG definida em: `airflow/dags/dbt_pipeline_dag.py` `airflow/dags/dbt_pipeline_dag_modular.py`
- Projeto DBT disponÃ­vel em: `airflow/dags/movie_stream_dbt/`

## ğŸ³ Docker e Airflow

O ambiente foi configurado com `docker-compose`, contendo os serviÃ§os:
- `postgres`: banco de metadados
- `airflow-webserver`: interface web
- `airflow-scheduler`: orquestrador
- `airflow-init`: inicializador do Airflow

## ğŸ§ª Testes e Logs

A interface permite execuÃ§Ã£o manual, agendada e visualizaÃ§Ã£o de logs por tarefa.
![Iniciar Airflow](<imagens/airflow instal.png>)
---

Desenvolvido por Elen de Bona âœ¨

PrÃ³ximo passo >>[Etapa 2 - DBT](README_dbt.md)